{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/upadhyayprakash/EIP/blob/master/MNIST_NN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nwwGHrYmddLO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "a3911c54-80f4-451f-d3c6-6c1379fb64af"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# X_train -> Image sources\n",
        "# y_train -> Output Digits like 0, 3, 5 etc.\n",
        "\n",
        "print(X_train.shape)\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[3])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcc3e7aa208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H+hFFaeMRqzlgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcca07302e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dZcbZ5p-fj7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "e15bbe99-0673-4dc3-9efa-877c475d65ea"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[120])\n",
        "\n",
        "# Working with Reshape. Dividing the pixels (0 to 255) by 255 to normalize them between 0 to 1\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "\n",
        "X_train /=255\n",
        "X_test /=255\n",
        "\n",
        "print(y_train[:10])\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10) # Converting to Hot Vector. E.g. 3 being converted to '0001000000'\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print (y_train[:10])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAG+3DoFAAEpYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcc7c0937f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SsOqm0O0kydv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "outputId": "0f2fa112-c961-4f5f-fbce-caf19e756a5c"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[120])\n",
        "\n",
        "# Working with Reshape. Dividing the pixels (0 to 255) by 255 to normalize them between 0 to 1\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "\n",
        "X_train /=255\n",
        "X_test /=255\n",
        "\n",
        "print(y_train[:10])\n",
        "\n",
        "# Working to make\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10) # Converting to Hot Vector. E.g. 3 being converted to '0001000000'\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print (y_train[:10])\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(Flatten()) # \n",
        "model.add(Dense(10, activation='softmax')) # Softmax is a loss function\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# 'adam' is the algorithm to control the learning rate.\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, nb_epoch=5, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0) # This score will validate the model accuracy.\n",
        "\n",
        "print (score)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 21632)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                216330    \n",
            "=================================================================\n",
            "Total params: 216,650\n",
            "Trainable params: 216,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 17s 284us/step - loss: 0.1746 - acc: 0.9493\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0706 - acc: 0.9788\n",
            "Epoch 3/5\n",
            "13760/60000 [=====>........................] - ETA: 11s - loss: 0.0442 - acc: 0.9862"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0506 - acc: 0.9843\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 15s 253us/step - loss: 0.0379 - acc: 0.9879\n",
            "Epoch 5/5\n",
            "23104/60000 [==========>...................] - ETA: 9s - loss: 0.0252 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 15s 252us/step - loss: 0.0286 - acc: 0.9908\n",
            "[0.06416295770022552, 0.9808]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAG+3DoFAAEpYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcc3e7aa518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Aau1VLzloQb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1135
        },
        "outputId": "bdeeda42-2d10-4932-cbb0-de33ad558a6d"
      },
      "cell_type": "code",
      "source": [
        "# Snippet-4:\n",
        "!pip install -q keras\n",
        "\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(X_train.shape)\n",
        "from  matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[120])\n",
        "\n",
        "# Working with Reshape. Dividing the pixels (0 to 255) by 255 to normalize them between 0 to 1\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "\n",
        "X_train /=255\n",
        "X_test /=255\n",
        "\n",
        "print(y_train[:10])\n",
        "\n",
        "# Working to make\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10) # Converting to Hot Vector. E.g. 3 being converted to '0001000000'\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print (y_train[:10])\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# 'adam' is the algorithm to control the learning rate.\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=32, nb_epoch=5, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0) # This score will validate the model accuracy.\n",
        "\n",
        "print (score)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "[5 0 4 1 9 2 1 3 1 4]\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 600,810\n",
            "Trainable params: 600,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10208/60000 [====>.........................] - ETA: 18s - loss: 0.5152 - acc: 0.8391"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 21s 347us/step - loss: 0.2034 - acc: 0.9382\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 20s 333us/step - loss: 0.0853 - acc: 0.9744\n",
            "Epoch 3/5\n",
            " 2112/60000 [>.............................] - ETA: 19s - loss: 0.0483 - acc: 0.9877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 20s 331us/step - loss: 0.0672 - acc: 0.9796\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 20s 326us/step - loss: 0.0536 - acc: 0.9840\n",
            "Epoch 5/5\n",
            "  672/60000 [..............................] - ETA: 19s - loss: 0.0434 - acc: 0.9836"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 19s 321us/step - loss: 0.0471 - acc: 0.9859\n",
            "[0.027154885865583674, 0.9918]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAG+3DoFAAEpYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fcc38136160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6Z6ZIbGBtE_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        },
        "outputId": "4b12ef54-3c63-4e92-b059-bfa2cba9dadd"
      },
      "cell_type": "code",
      "source": [
        "# Day-4\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, Add, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils \n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "X = Conv2D(32, (3, 3), padding = 'same', activation='relu')(inputs)\n",
        "X = Conv2D(64, (3, 3), activation='relu')(X)\n",
        "X = MaxPooling2D((2, 2))(X)\n",
        "X = Dropout(0.25)(X)\n",
        "X = Flatten()(X)\n",
        "X = Dense(196, activation='relu')(X)\n",
        "recon = MaxPooling2D((2, 2))(inputs)\n",
        "recon = Reshape((196,), input_shape=(28, 28))(recon)\n",
        "X = Add()([recon, X])\n",
        "X = Dropout(0.5)(X)\n",
        "output = Dense(num_classes, activation='softmax')(X)\n",
        "model = Model(inputs=[inputs], outputs=[output])\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, \n",
        "             optimizer=keras.optimizers.Adadelta(),\n",
        "             metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs = epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 26, 26, 64)   18496       conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 64)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 13, 13, 64)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 10816)        0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 196)          0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 196)          2120132     flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 196)          0           reshape_1[0][0]                  \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 196)          0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           1970        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,140,918\n",
            "Trainable params: 2,140,918\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            " 7296/60000 [==>...........................] - ETA: 14s - loss: 0.9748 - acc: 0.6790"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.2786 - acc: 0.9128 - val_loss: 0.0550 - val_acc: 0.9826\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0904 - acc: 0.9725 - val_loss: 0.0405 - val_acc: 0.9859\n",
            "Epoch 3/12\n",
            "21376/60000 [=========>....................] - ETA: 8s - loss: 0.0665 - acc: 0.9800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0658 - acc: 0.9798 - val_loss: 0.0355 - val_acc: 0.9881\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0546 - acc: 0.9837 - val_loss: 0.0321 - val_acc: 0.9895\n",
            "Epoch 5/12\n",
            "24704/60000 [===========>..................] - ETA: 7s - loss: 0.0450 - acc: 0.9863"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0460 - acc: 0.9861 - val_loss: 0.0298 - val_acc: 0.9895\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0407 - acc: 0.9871 - val_loss: 0.0258 - val_acc: 0.9908\n",
            "Epoch 7/12\n",
            "25472/60000 [===========>..................] - ETA: 7s - loss: 0.0373 - acc: 0.9885"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.0377 - acc: 0.9887 - val_loss: 0.0262 - val_acc: 0.9912\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0255 - val_acc: 0.9913\n",
            "Epoch 9/12\n",
            "25472/60000 [===========>..................] - ETA: 7s - loss: 0.0320 - acc: 0.9903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 13s 218us/step - loss: 0.0326 - acc: 0.9903 - val_loss: 0.0264 - val_acc: 0.9912\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 13s 221us/step - loss: 0.0281 - acc: 0.9913 - val_loss: 0.0281 - val_acc: 0.9909\n",
            "Epoch 11/12\n",
            "25216/60000 [===========>..................] - ETA: 7s - loss: 0.0250 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 13s 219us/step - loss: 0.0266 - acc: 0.9918 - val_loss: 0.0271 - val_acc: 0.9914\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 13s 220us/step - loss: 0.0246 - acc: 0.9925 - val_loss: 0.0270 - val_acc: 0.9917\n",
            "Test loss: 0.02701228699438652\n",
            "Test accuracy: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6NA6HB9Ej8WT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "e9bdd2e1-e119-41da-ac38-cdd0d98e34b5"
      },
      "cell_type": "code",
      "source": [
        "# Take Input from previous code block to giving layer name to this code.\n",
        "# ========== Block - 2\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(x_train[9]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_15'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Saliency map\n",
        "# https://github.com/experiencor/deep-viz-keras/blob/master/saliency.py\n",
        "from keras.layers import Input, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.initializers import Ones, Zeros\n",
        "\n",
        "class SaliencyMask(object):\n",
        "    def __init__(self, model, output_index=0):\n",
        "        pass\n",
        "\n",
        "    def get_mask(self, input_image):\n",
        "        pass\n",
        "\n",
        "    def get_smoothed_mask(self, input_image, stdev_spread=.2, nsamples=50):\n",
        "        stdev = stdev_spread * (np.max(input_image) - np.min(input_image))\n",
        "\n",
        "        total_gradients = np.zeros_like(input_image, dtype = np.float64)\n",
        "        for i in range(nsamples):\n",
        "            noise = np.random.normal(0, stdev, input_image.shape)\n",
        "            x_value_plus_noise = input_image + noise\n",
        "\n",
        "            total_gradients += self.get_mask(x_value_plus_noise)\n",
        "\n",
        "        return total_gradients / nsamples\n",
        "\n",
        "class GradientSaliency(SaliencyMask):\n",
        "\n",
        "    def __init__(self, model, output_index = 0):\n",
        "        # Define the function to compute the gradient\n",
        "        input_tensors = [model.input]\n",
        "        gradients = model.optimizer.get_gradients(model.output[0][output_index], model.input)\n",
        "        self.compute_gradients = K.function(inputs = input_tensors, outputs = gradients)\n",
        "\n",
        "    def get_mask(self, input_image):\n",
        "        # Execute the function to compute the gradient\n",
        "        x_value = np.expand_dims(input_image, axis=0)\n",
        "        gradients = self.compute_gradients([x_value])[0][0]\n",
        "\n",
        "        return gradients\n",
        "\n",
        "# https://github.com/experiencor/deep-viz-keras/blob/master/visual_backprop.py\n",
        "class VisualBackprop(SaliencyMask):\n",
        "    def __init__(self, model, output_index = 0):\n",
        "        inps = [model.input]           # input placeholder\n",
        "        outs = [layer.output for layer in model.layers]    # all layer outputs\n",
        "        self.forward_pass = K.function(inps, outs)         # evaluation function\n",
        "        \n",
        "        self.model = model\n",
        "\n",
        "    def get_mask(self, input_image):\n",
        "        x_value = np.expand_dims(input_image, axis=0)\n",
        "        \n",
        "        visual_bpr = None\n",
        "        layer_outs = self.forward_pass([x_value, 0])\n",
        "\n",
        "        for i in range(len(self.model.layers) - 1, -1, -1):\n",
        "            if 'Conv2D' in str(type(self.model.layers[i])):\n",
        "                layer = np.mean(layer_outs[i], axis = 3, keepdims = True)\n",
        "                layer = layer - np.min(layer)\n",
        "                layer = layer / (np.max(layer) - np.min(layer) + 1e-6)\n",
        "\n",
        "                if visual_bpr is not None:\n",
        "                    if visual_bpr.shape != layer.shape:\n",
        "                        visual_bpr = self._deconv(visual_bpr)\n",
        "                    visual_bpr = visual_bpr * layer\n",
        "                else:\n",
        "                    visual_bpr = layer\n",
        "\n",
        "        return visual_bpr[0]\n",
        "    \n",
        "    def _deconv(self, feature_map):\n",
        "        x = Input(shape = (None, None, 1))\n",
        "        y = Conv2DTranspose(filters = 1, \n",
        "                            kernel_size = (3, 3), \n",
        "                            strides = (2, 2), \n",
        "                            padding = 'same', \n",
        "                            kernel_initializer = Ones(), \n",
        "                            bias_initializer = Zeros())(x)\n",
        "\n",
        "        deconv_model = Model(inputs=[x], outputs=[y])\n",
        "\n",
        "        inps = [deconv_model.input]   # input placeholder                                \n",
        "        outs = [deconv_model.layers[-1].output]           # output placeholder\n",
        "        deconv_func = K.function(inps, outs)              # evaluation function\n",
        "        \n",
        "        return deconv_func([feature_map, 0])[0]\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn import preprocessing\n",
        "\n",
        "Y_train_label = range(10)\n",
        "\n",
        "fig, ax = plt.subplots(10, 5, figsize = (12, 16))\n",
        "fig.suptitle('vanilla gradient')\n",
        "for i in range(num_classes):\n",
        "    img = np.array(x_train[i])\n",
        "    \n",
        "    vanilla = GradientSaliency(model, Y_train_label[i])\n",
        "    mask = vanilla.get_mask(img)\n",
        "    filter_mask = (mask > 0.0).reshape((28, 28))\n",
        "    smooth_mask = vanilla.get_smoothed_mask(img)\n",
        "    filter_smoothed_mask = (smooth_mask > 0.0).reshape((28, 28))\n",
        "\n",
        "    ax[i, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    cax = ax[i, 1].imshow(mask.reshape((28, 28)), cmap = 'jet')\n",
        "    fig.colorbar(cax, ax = ax[i, 1])\n",
        "    ax[i, 2].imshow(mask.reshape((28, 28)) * filter_mask, cmap = 'gray')\n",
        "    cax = ax[i, 3].imshow(mask.reshape((28, 28)), cmap = 'jet')\n",
        "    fig.colorbar(cax, ax = ax[i, 3])\n",
        "    ax[i, 4].imshow(smooth_mask.reshape((28, 28)) * filter_smoothed_mask, cmap = 'gray')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0ed53529907b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplot_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mvis_img_in_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0ed53529907b>\u001b[0m in \u001b[0;36mvis_img_in_filter\u001b[0;34m(img, layer_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m def vis_img_in_filter(img = np.array(x_train[9]).reshape((1, 28, 28, 1)).astype(np.float64), \n\u001b[1;32m     24\u001b[0m                       layer_name = 'conv2d_15'):\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mimg_ascs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilter_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'conv2d_15'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hN9fOAEPkc1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "b0b7d254-a072-420a-abbd-564ecf6f2d0f"
      },
      "cell_type": "code",
      "source": [
        "# Hands-On Day 5\n",
        "# RNN\n",
        "# Description: X -> If you sleep for 2 hours and Study for 9 hours, you'll get y as 92 etc..\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# X = (hours sleeping, hours studying), y = score on test\n",
        "X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)\n",
        "print(X)\n",
        "\n",
        "y = np.array(([92], [76], [80]), dtype=float)\n",
        "print(y)\n",
        "\n",
        "# scale units\n",
        "X = X/np.amax(X, axis=0) # scaling values between 0 an 1, or Normalizing the values\n",
        "print(X)\n",
        "y = y/100 # max test score is 100\n",
        "print(y)\n",
        "\n",
        "class Neural_Network(object):\n",
        "    def __init__(self):\n",
        "        #parameters\n",
        "        self.inputSize = 2\n",
        "        self.outputSize = 1\n",
        "        self.hiddenSize = 3\n",
        "        \n",
        "        #weights\n",
        "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) # (2x3) weight matrix from input to hidden layer\n",
        "        \n",
        "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) # (3x1) weight matrix from hidden to output layer\n",
        "        \n",
        "    def forward(self, X):\n",
        "        #forward propagation through our network\n",
        "        self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights\n",
        "        self.z2 = self.sigmoid(self.z) # activation function\n",
        "        self.z3 = np.dot(self.z2, self.W2) # dot product of hidden layer (z2) and secont set of 3x1 weights\n",
        "        output = self.sigmoid(self.z3) # final activation function\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def sigmoid(self, s):\n",
        "        # activation function\n",
        "        return 1/(1 + np.exp(-s))\n",
        "    \n",
        "    def sigmoidPrime(self, s):\n",
        "        # derivation of sigmoid\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    def backward(self, X, y, output):\n",
        "        # backward propagate through the network\n",
        "        \n",
        "        # error in output\n",
        "        self.output_error = y - output \n",
        "        \n",
        "        # applying derivative of sigmoid to error \n",
        "        self.output_delta = self.output_error*self.sigmoidPrime(output)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # z2 error: how much our hidden weights contributed to the output error?\n",
        "        self.z2_error = self.output_delta.dot(self.W2.T)\n",
        "        \n",
        "        # applying derative of sigmoid to z2 error\n",
        "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2)\n",
        "        \n",
        "        # update the weights (input --> hidden)\n",
        "        self.W1 += X.T.dot(self.z2_delta)\n",
        "        \n",
        "        # update the second set (hidden --> output) of weights\n",
        "        self.W2 += self.z2.T.dot(self.output_delta)\n",
        "    \n",
        "    def train(self, X, y):\n",
        "        output = self.forward(X)\n",
        "        self.backward(X, y, output)\n",
        "\n",
        "NN = Neural_Network()\n",
        "\n",
        "print (\"Input: \\n\" + str(X))\n",
        "print (\"Actual Output: \\n\" + str(y))\n",
        "for i in range(10000): # train the NN 1000 times\n",
        "    if i % 2000 == 0:\n",
        "        print (\"Predicted Output: \\n\" + str(NN.forward(X)))\n",
        "        # mean sum squared loss\n",
        "        print (\"Loss: \\n\" + str(np.mean(np.square(y - NN.forward(X))))) \n",
        "        print (\"\\n\")\n",
        "    NN.train(X, y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 9.]\n",
            " [1. 5.]\n",
            " [3. 6.]]\n",
            "[[92.]\n",
            " [76.]\n",
            " [80.]]\n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "[[0.92]\n",
            " [0.76]\n",
            " [0.8 ]]\n",
            "Input: \n",
            "[[0.66666667 1.        ]\n",
            " [0.33333333 0.55555556]\n",
            " [1.         0.66666667]]\n",
            "Actual Output: \n",
            "[[0.92]\n",
            " [0.76]\n",
            " [0.8 ]]\n",
            "Predicted Output: \n",
            "[[0.1086289 ]\n",
            " [0.13004604]\n",
            " [0.12323231]]\n",
            "Loss: \n",
            "0.5043931852437886\n",
            "\n",
            "\n",
            "Predicted Output: \n",
            "[[0.866688  ]\n",
            " [0.79663386]\n",
            " [0.80594852]]\n",
            "Loss: \n",
            "0.001406531017671444\n",
            "\n",
            "\n",
            "Predicted Output: \n",
            "[[0.88386848]\n",
            " [0.78105724]\n",
            " [0.80319197]]\n",
            "Loss: \n",
            "0.0005863608931741162\n",
            "\n",
            "\n",
            "Predicted Output: \n",
            "[[0.89532025]\n",
            " [0.77274194]\n",
            " [0.80186254]]\n",
            "Loss: \n",
            "0.00025830530057679556\n",
            "\n",
            "\n",
            "Predicted Output: \n",
            "[[0.90350112]\n",
            " [0.76774241]\n",
            " [0.80115528]]\n",
            "Loss: \n",
            "0.00011116427962184657\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8hsNAWNzwR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c1bc6dba-bcdc-454b-dc5a-488d63af50a6"
      },
      "cell_type": "code",
      "source": [
        "import copy, numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# compute Sigmoid nonlinearity\n",
        "def Sigmoid(x):\n",
        "    output = 1/(1+np.exp(-x))\n",
        "    return output\n",
        "\n",
        "def Sigmoid_backprop(output):\n",
        "    return output*(1-output)\n",
        "\n",
        "# training data\n",
        "int2binary = {}\n",
        "largest_number = 256\n",
        "\n",
        "binary = np.unpackbits(\n",
        "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "for i in range(largest_number):\n",
        "    int2binary[i] = binary[i]\n",
        "    \n",
        "# hyperparams\n",
        "\n",
        "learning_rate = 0.1\n",
        "input_dim = 2\n",
        "hidden_dim = 16\n",
        "output_dim = 1\n",
        "\n",
        "# initialize neural network weights\n",
        "weights_x = 2*np.random.random((input_dim, hidden_dim)) -1\n",
        "weights_hh = 2*np.random.random((hidden_dim, hidden_dim)) -1\n",
        "weights_hy = 2*np.random.random((hidden_dim, output_dim)) -1\n",
        "\n",
        "layer_rnn = Sigmoid (np.dot(X, weights_x) + \n",
        "                          np.dot (layer_rnn_values[-1], weights_hh) )\n",
        "        \n",
        "# output layer (new binary representation)\n",
        "layer_y = Sigmoid (np.dot (layer_rnn, weights_hy) )\n",
        "\n",
        "\n",
        "weights_x_update = np.zeros_like(weights_x)\n",
        "weights_hh_update = np.zeros_like(weights_hh)\n",
        "weights_hy_update = np.zeros_like(weights_hy)\n",
        "\n",
        "# training logic\n",
        "\n",
        "for i in range(10000):\n",
        "    # generate a simple addition problem (a + b = c)\n",
        "    a_int = np.random.randint(largest_number/2) # int version\n",
        "    a = int2binary[a_int] # binary encoding\n",
        "\n",
        "    b_int = np.random.randint(largest_number/2) # int version\n",
        "    b = int2binary[b_int] # binary encoding\n",
        "\n",
        "    # true answer\n",
        "    c_int = a_int + b_int\n",
        "    c = int2binary[c_int]\n",
        "    \n",
        "    # where we'll store our best guess (binary encoded)\n",
        "    d = np.zeros_like(c)\n",
        "\n",
        "    overallError = 0\n",
        "    \n",
        "    layer_y_deltas = list()\n",
        "    layer_rnn_values = list()\n",
        "    layer_rnn_values.append(np.zeros(hidden_dim))\n",
        "    \n",
        "    # moving along the position in the binary encoding bit by bit\n",
        "    for position in range(8):\n",
        "        \n",
        "        # generate input and output\n",
        "        X = np.array([[a[8 - position - 1], b[8 - position - 1]]])\n",
        "        y = np.array([[c[8 - position - 1]]]).T\n",
        "        \n",
        "        # hidden layer (input ~+ prev_hidden)\n",
        "        layer_rnn = Sigmoid(np.dot(X, weights_x) + np.dot(layer_rnn_values[-1], weights_hh))\n",
        "        \n",
        "        # output layer (new binary representation)\n",
        "        layer_y = Sigmoid(np.dot(layer_rnn, weights_hy))\n",
        "\n",
        "        \n",
        "        # error\n",
        "        layer_y_error = y - layer_y\n",
        "        layer_y_deltas.append((layer_y_error)*Sigmoid_backprop(layer_y))\n",
        "        \n",
        "        overallError += np.abs(layer_y_error[0])     \n",
        "        \n",
        "        # decode estimate so we can print it out\n",
        "        d[8 - position - 1] = np.round(layer_y[0][0])\n",
        "        \n",
        "        # store hidden layer so we can use it in the next timestep\n",
        "        layer_rnn_values.append(copy.deepcopy(layer_rnn))\n",
        "    \n",
        "    future_layer_rnn_delta = np.zeros(hidden_dim)\n",
        "    \n",
        "    for position in range(8):\n",
        "        \n",
        "        X = np.array([[a[position], b[position]]])\n",
        "        layer_rnn = layer_rnn_values[-position - 1]\n",
        "        prev_layer_rnn = layer_rnn_values[-position - 2]\n",
        "        \n",
        "        # error at output layer\n",
        "        layer_y_delta = layer_y_deltas[-position - 1]\n",
        "        # error at hidden layer\n",
        "        layer_rnn_delta = (future_layer_rnn_delta.dot(weights_hh.T) + \n",
        "                         layer_y_delta.dot(weights_hy.T))*Sigmoid_backprop(layer_rnn)\n",
        "        \n",
        "        \n",
        "        # let's update all our weights so we can try again\n",
        "        weights_hy_update += np.atleast_2d(layer_rnn).T.dot(layer_y_delta)\n",
        "        weights_hh_update += np.atleast_2d(prev_layer_rnn).T.dot(layer_rnn_delta)\n",
        "        weights_x_update += X.T.dot(layer_rnn_delta)\n",
        "        \n",
        "        future_layer_rnn_delta = layer_rnn_delta\n",
        "    \n",
        "    # let's update the weights\n",
        "    weights_x += weights_x_update * learning_rate\n",
        "    weights_hh += weights_hh_update * learning_rate\n",
        "    weights_hy += weights_hy_update * learning_rate\n",
        "    \n",
        "    weights_x_update *= 0\n",
        "    weights_hh_update *= 0\n",
        "    weights_hy_update *= 0\n",
        "    \n",
        "    #print out progress\n",
        "    if (i % 1000 == 0):\n",
        "        print(\"Error: \" + str(overallError))\n",
        "        print(\"Pred: \" + str(d))\n",
        "        print(\"True: \" + str(c))\n",
        "        out = 0\n",
        "        for index, x in enumerate(reversed(d)):\n",
        "            out += x*pow(2, index)\n",
        "        print (str(a_int) + \" + \" + str(b_int) + \" = \" + str(out))\n",
        "        print (\"--------\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7a524bf26e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m layer_rnn = Sigmoid (np.dot(X, weights_x) + \n\u001b[0;32m---> 35\u001b[0;31m                           np.dot (layer_rnn_values[-1], weights_hh) )\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# output layer (new binary representation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layer_rnn_values' is not defined"
          ]
        }
      ]
    }
  ]
}