{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/upadhyayprakash/EIP/blob/master/PRAKASH_BATCH_3_ASSIGNMENT4B_NEW.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "3pX4qUUIgp85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Attempt-2: Assigment 4B of EIP Batch 3 - Prakash Upadhyay**</br>\n",
        "**Task: ** Beat the Validation Score of **76.09%** accuracy.\n",
        "\n",
        "- Acquired Accuracy: **84.17%**"
      ]
    },
    {
      "metadata": {
        "id": "byRG38kNw2Ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dah8vTtgw42M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU # Added by Prakash\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJZ7RoHrxDkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3iA2TlhxWDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 40\n",
        "l = 40\n",
        "num_filter = 32\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09MBU7xrxaZI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# Added by Prakash\n",
        "#x_train = x_train.astype('float32')\n",
        "#x_test = x_test.astype('float32')\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3trOb3i1yG0a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pjdk3Ezgy-Gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXRiNCR30DQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    #AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    #flat = Flatten()(AvgPooling)\n",
        "    flat = Flatten()(relu)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-jN6M0-0FUJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_filter = 32\n",
        "dropout_rate = 0.2\n",
        "l = 12\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "# START: Added Pooling & Dropout by Prakash\n",
        "\n",
        "Second_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(First_Conv2D)\n",
        "DropOut_Conv2D = Dropout(0.2)(Second_Conv2D)\n",
        "AvgPooling2D_Conv2D = AveragePooling2D(pool_size=(2,2))(DropOut_Conv2D)\n",
        "\n",
        "# END: Added Pooling & Dropout by Prakash\n",
        "\n",
        "\n",
        "# START: Added Pooling & Dropout by Prakash\n",
        "#BatchNorm = BatchNormalization()(input)\n",
        "#relu = Activation('relu')(BatchNorm)\n",
        "    \n",
        "#Second_Conv2D = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "\n",
        "#DropOut_Conv2D = Dropout(0.2)(Second_Conv2D)\n",
        "#AvgPooling2D_Conv2D = AveragePooling2D(pool_size=(2,2))(DropOut_Conv2D)\n",
        "\n",
        "# END: Added Pooling & Dropout by Prakash\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "#Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "#Last_Block = add_denseblock(Third_Block,  num_filter, dropout_rate)\n",
        "\n",
        "output = output_layer(Third_Block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wPrDqJH0Xv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7926
        },
        "outputId": "8e6c3d7d-f5d3-44ad-b025-138301c26f8e"
      },
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 32, 32, 32)   864         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 32, 32, 32)   128         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 32, 32, 32)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 32, 32, 16)   4608        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 32, 32, 16)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 32, 32, 48)   0           conv2d_121[0][0]                 \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 32, 32, 48)   192         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 32, 32, 48)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 32, 32, 16)   6912        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 32, 32, 16)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 32, 32, 64)   0           concatenate_109[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 32, 32, 64)   256         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 32, 32, 64)   0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 32, 32, 16)   9216        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 32, 32, 16)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 32, 32, 80)   0           concatenate_110[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 32, 32, 80)   320         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 32, 32, 80)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 32, 32, 16)   11520       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 32, 32, 16)   0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 32, 32, 96)   0           concatenate_111[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 32, 32, 96)   384         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 32, 32, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 32, 32, 16)   13824       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 32, 32, 16)   0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 32, 32, 112)  0           concatenate_112[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 32, 32, 112)  448         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 32, 32, 112)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 32, 32, 16)   16128       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 32, 32, 16)   0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 32, 32, 128)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 32, 32, 128)  512         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 32, 32, 128)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 32, 32, 16)   18432       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 32, 32, 16)   0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 32, 32, 144)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 32, 32, 144)  576         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 32, 32, 144)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 32, 32, 16)   20736       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 32, 32, 16)   0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 32, 32, 160)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 32, 32, 160)  640         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 32, 32, 160)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 32, 32, 16)   23040       activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 32, 32, 16)   0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 32, 32, 176)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 32, 32, 176)  704         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 32, 32, 176)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 32, 32, 16)   25344       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 32, 32, 16)   0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 32, 32, 192)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 32, 32, 192)  768         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 32, 32, 192)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 32, 32, 16)   27648       activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 32, 32, 16)   0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 32, 32, 208)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 32, 32, 208)  832         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 32, 32, 208)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 32, 32, 16)   29952       activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 32, 32, 16)   0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 32, 32, 224)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 32, 32, 224)  896         concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 32, 32, 224)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 32, 32, 16)   3584        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 32, 32, 16)   0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 16)   0           dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 16, 16, 16)   64          average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 16, 16, 16)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 16)   2304        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 16, 16, 16)   0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 16, 16, 32)   0           average_pooling2d_11[0][0]       \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 16, 16, 32)   128         concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 16, 16, 32)   0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 16)   4608        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 16, 16, 16)   0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 16, 16, 48)   0           concatenate_121[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 16, 16, 48)   192         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 16, 16, 48)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 16)   6912        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 16, 16, 16)   0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 16, 16, 64)   0           concatenate_122[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 16, 16, 64)   256         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 16, 16, 64)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 16, 16, 16)   9216        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 16, 16, 16)   0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 16, 16, 80)   0           concatenate_123[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 16, 16, 80)   320         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 16, 16, 80)   0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 16, 16, 16)   11520       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 16, 16, 16)   0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 16, 16, 96)   0           concatenate_124[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 16, 16, 96)   384         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 16, 16, 96)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 16, 16, 16)   13824       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 16, 16, 16)   0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 16, 16, 112)  0           concatenate_125[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 16, 16, 112)  448         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 16, 16, 112)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 16, 16, 16)   16128       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 16, 16, 16)   0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 16, 16, 128)  0           concatenate_126[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 16, 16, 128)  512         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 16, 16, 128)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 16, 16, 16)   18432       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 16, 16, 16)   0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 16, 16, 144)  0           concatenate_127[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 16, 16, 144)  576         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 16, 16, 144)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 16, 16, 16)   20736       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 16, 16, 16)   0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 16, 16, 160)  0           concatenate_128[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 16, 16, 160)  640         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 16, 16, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 16, 16, 16)   23040       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 16, 16, 16)   0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 16, 16, 176)  0           concatenate_129[0][0]            \n",
            "                                                                 dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 16, 16, 176)  704         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 16, 16, 176)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 16, 16, 16)   25344       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 16, 16, 16)   0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 16, 16, 192)  0           concatenate_130[0][0]            \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 16, 16, 192)  768         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 16, 16, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 16, 16, 16)   27648       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 16, 16, 16)   0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 16, 16, 208)  0           concatenate_131[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 16, 16, 208)  832         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 16, 16, 208)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 16, 16, 16)   3328        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 16, 16, 16)   0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 8, 8, 16)     0           dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 8, 8, 16)     64          average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 8, 8, 16)     0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 8, 8, 16)     2304        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 8, 8, 16)     0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 8, 8, 32)     0           average_pooling2d_12[0][0]       \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 8, 8, 32)     128         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 8, 8, 32)     0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 8, 8, 16)     4608        activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 8, 8, 16)     0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 8, 8, 48)     0           concatenate_133[0][0]            \n",
            "                                                                 dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 8, 8, 48)     192         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8, 8, 48)     0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 8, 8, 16)     6912        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 8, 8, 16)     0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 8, 8, 64)     0           concatenate_134[0][0]            \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 8, 8, 64)     256         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8, 8, 64)     0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 8, 8, 16)     9216        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 8, 8, 16)     0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 8, 8, 80)     0           concatenate_135[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 8, 8, 80)     320         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 8, 8, 80)     0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 8, 8, 16)     11520       activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 8, 8, 16)     0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 8, 8, 96)     0           concatenate_136[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 8, 8, 96)     384         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 8, 8, 96)     0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 8, 8, 16)     13824       activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 8, 8, 16)     0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 8, 8, 112)    0           concatenate_137[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 8, 8, 112)    448         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 8, 8, 112)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 8, 8, 16)     16128       activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 8, 8, 16)     0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 8, 8, 128)    0           concatenate_138[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 8, 8, 128)    512         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 8, 8, 128)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 8, 8, 16)     18432       activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 8, 8, 16)     0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 8, 8, 144)    0           concatenate_139[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 8, 8, 144)    576         concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 8, 8, 144)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 8, 8, 16)     20736       activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 8, 8, 16)     0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 8, 8, 160)    0           concatenate_140[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 8, 8, 160)    640         concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 8, 8, 160)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 8, 8, 16)     23040       activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_154 (Dropout)           (None, 8, 8, 16)     0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 8, 8, 176)    0           concatenate_141[0][0]            \n",
            "                                                                 dropout_154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 8, 8, 176)    704         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 8, 8, 176)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 8, 8, 16)     25344       activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_155 (Dropout)           (None, 8, 8, 16)     0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 8, 8, 192)    0           concatenate_142[0][0]            \n",
            "                                                                 dropout_155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 8, 8, 192)    768         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 8, 8, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 8, 8, 16)     27648       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_156 (Dropout)           (None, 8, 8, 16)     0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 8, 8, 208)    0           concatenate_143[0][0]            \n",
            "                                                                 dropout_156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 8, 8, 208)    832         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 8, 8, 208)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 13312)        0           activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           133130      flatten_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 725,994\n",
            "Trainable params: 716,842\n",
            "Non-trainable params: 9,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SL232Gi1Gcd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1l2ZEe3N1N4H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1528
        },
        "outputId": "61694792-8697-420f-9073-3940c45dfcfc"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "50000/50000 [==============================] - 288s 6ms/step - loss: 1.6660 - acc: 0.4429 - val_loss: 2.0007 - val_acc: 0.4004\n",
            "Epoch 2/40\n",
            "19200/50000 [==========>...................] - ETA: 2:37 - loss: 1.2891 - acc: 0.5742"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 1.2555 - acc: 0.5869 - val_loss: 1.2960 - val_acc: 0.5723\n",
            "Epoch 3/40\n",
            "45568/50000 [==========================>...] - ETA: 22s - loss: 1.0516 - acc: 0.6539"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 1.0467 - acc: 0.6549 - val_loss: 1.4772 - val_acc: 0.6026\n",
            "Epoch 4/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.9111 - acc: 0.6991 - val_loss: 0.9236 - val_acc: 0.6914\n",
            "Epoch 5/40\n",
            " 3328/50000 [>.............................] - ETA: 3:58 - loss: 0.8319 - acc: 0.7323"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.7954 - acc: 0.7341 - val_loss: 0.8287 - val_acc: 0.7294\n",
            "Epoch 6/40\n",
            "39424/50000 [======================>.......] - ETA: 54s - loss: 0.6845 - acc: 0.7648"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.6816 - acc: 0.7656 - val_loss: 0.8410 - val_acc: 0.7190\n",
            "Epoch 7/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.6158 - acc: 0.7852 - val_loss: 0.7972 - val_acc: 0.7414\n",
            "Epoch 8/40\n",
            " 1792/50000 [>.............................] - ETA: 4:08 - loss: 0.5363 - acc: 0.8047"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 277s 6ms/step - loss: 0.5597 - acc: 0.8042 - val_loss: 0.8355 - val_acc: 0.7388\n",
            "Epoch 9/40\n",
            "38912/50000 [======================>.......] - ETA: 57s - loss: 0.5137 - acc: 0.8210"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.5130 - acc: 0.8206 - val_loss: 0.9140 - val_acc: 0.7300\n",
            "Epoch 10/40\n",
            "50000/50000 [==============================] - 277s 6ms/step - loss: 0.4695 - acc: 0.8363 - val_loss: 0.6876 - val_acc: 0.7838\n",
            "Epoch 11/40\n",
            " 1536/50000 [..............................] - ETA: 4:09 - loss: 0.4420 - acc: 0.8411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.4322 - acc: 0.8499 - val_loss: 0.6574 - val_acc: 0.7864\n",
            "Epoch 12/40\n",
            "38528/50000 [======================>.......] - ETA: 59s - loss: 0.3988 - acc: 0.8599"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.4034 - acc: 0.8578 - val_loss: 0.7372 - val_acc: 0.7757\n",
            "Epoch 13/40\n",
            "50000/50000 [==============================] - 277s 6ms/step - loss: 0.3723 - acc: 0.8686 - val_loss: 0.6853 - val_acc: 0.7862\n",
            "Epoch 14/40\n",
            " 1536/50000 [..............................] - ETA: 4:09 - loss: 0.3048 - acc: 0.8893"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.3571 - acc: 0.8739 - val_loss: 0.6491 - val_acc: 0.8112\n",
            "Epoch 15/40\n",
            "38528/50000 [======================>.......] - ETA: 59s - loss: 0.3246 - acc: 0.8842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.3270 - acc: 0.8832 - val_loss: 0.9986 - val_acc: 0.7721\n",
            "Epoch 16/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.3031 - acc: 0.8929 - val_loss: 0.7371 - val_acc: 0.7883\n",
            "Epoch 17/40\n",
            " 1536/50000 [..............................] - ETA: 4:08 - loss: 0.2602 - acc: 0.9121"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.2805 - acc: 0.9001 - val_loss: 0.6808 - val_acc: 0.8101\n",
            "Epoch 18/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.2570 - acc: 0.9084"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.2655 - acc: 0.9059 - val_loss: 0.7859 - val_acc: 0.7968\n",
            "Epoch 19/40\n",
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.2529 - acc: 0.9086 - val_loss: 0.8200 - val_acc: 0.7962\n",
            "Epoch 20/40\n",
            " 1536/50000 [..............................] - ETA: 4:06 - loss: 0.2193 - acc: 0.9180"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.2308 - acc: 0.9173 - val_loss: 0.7300 - val_acc: 0.8053\n",
            "Epoch 21/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.2115 - acc: 0.9243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.2165 - acc: 0.9218 - val_loss: 0.7084 - val_acc: 0.8132\n",
            "Epoch 22/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.2087 - acc: 0.9251 - val_loss: 0.7321 - val_acc: 0.8130\n",
            "Epoch 23/40\n",
            " 1536/50000 [..............................] - ETA: 4:08 - loss: 0.1745 - acc: 0.9329"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1992 - acc: 0.9272 - val_loss: 0.7621 - val_acc: 0.8045\n",
            "Epoch 24/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.1815 - acc: 0.9338"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1866 - acc: 0.9323 - val_loss: 0.7439 - val_acc: 0.8142\n",
            "Epoch 25/40\n",
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1755 - acc: 0.9376 - val_loss: 0.8150 - val_acc: 0.8074\n",
            "Epoch 26/40\n",
            " 1536/50000 [..............................] - ETA: 4:07 - loss: 0.1392 - acc: 0.9538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1672 - acc: 0.9407 - val_loss: 0.7689 - val_acc: 0.8191\n",
            "Epoch 27/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.1510 - acc: 0.9451"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1556 - acc: 0.9431 - val_loss: 0.7263 - val_acc: 0.8328\n",
            "Epoch 28/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1540 - acc: 0.9436 - val_loss: 0.7289 - val_acc: 0.8221\n",
            "Epoch 29/40\n",
            " 1536/50000 [..............................] - ETA: 4:10 - loss: 0.1277 - acc: 0.9538"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1441 - acc: 0.9482 - val_loss: 0.9295 - val_acc: 0.7938\n",
            "Epoch 30/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.1386 - acc: 0.9507"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1408 - acc: 0.9496 - val_loss: 0.8622 - val_acc: 0.8157\n",
            "Epoch 31/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1334 - acc: 0.9506 - val_loss: 0.8323 - val_acc: 0.8245\n",
            "Epoch 32/40\n",
            " 1536/50000 [..............................] - ETA: 4:08 - loss: 0.1198 - acc: 0.9616"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1300 - acc: 0.9521 - val_loss: 0.7795 - val_acc: 0.8237\n",
            "Epoch 33/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.1166 - acc: 0.9581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1194 - acc: 0.9569 - val_loss: 0.9411 - val_acc: 0.7956\n",
            "Epoch 34/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1160 - acc: 0.9589 - val_loss: 0.8433 - val_acc: 0.8231\n",
            "Epoch 35/40\n",
            " 1536/50000 [..............................] - ETA: 4:08 - loss: 0.1023 - acc: 0.9642"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1146 - acc: 0.9572 - val_loss: 0.9205 - val_acc: 0.8120\n",
            "Epoch 36/40\n",
            "38528/50000 [======================>.......] - ETA: 59s - loss: 0.1115 - acc: 0.9602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1130 - acc: 0.9593 - val_loss: 0.7807 - val_acc: 0.8417\n",
            "Epoch 37/40\n",
            "50000/50000 [==============================] - 276s 6ms/step - loss: 0.1070 - acc: 0.9616 - val_loss: 0.8331 - val_acc: 0.8295\n",
            "Epoch 38/40\n",
            " 1536/50000 [..............................] - ETA: 4:08 - loss: 0.0847 - acc: 0.9674"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 5ms/step - loss: 0.1059 - acc: 0.9615 - val_loss: 0.7733 - val_acc: 0.8335\n",
            "Epoch 39/40\n",
            "38528/50000 [======================>.......] - ETA: 58s - loss: 0.1002 - acc: 0.9644"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.1031 - acc: 0.9635 - val_loss: 0.9342 - val_acc: 0.8153\n",
            "Epoch 40/40\n",
            "50000/50000 [==============================] - 275s 6ms/step - loss: 0.0966 - acc: 0.9656 - val_loss: 0.7715 - val_acc: 0.8381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d907fb668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "1mgDluhm1hKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a016bbc5-cd50-40a0-86a6-f11892655e1f"
      },
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 25s 3ms/step\n",
            "Test loss: 0.7715331559419631\n",
            "Test accuracy: 0.8381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
